from flask import Flask, request, jsonify
import cv2
import torch
import function.utils_rotate as utils_rotate
import function.helper as helper
import os
import base64
import numpy as np
import time
from werkzeug.utils import secure_filename
from flask_cors import CORS
from plate_memory import PlateMemoryManager

app = Flask(__name__)
CORS(app, resources={
    r"/*": {
        "origins": "*",
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})

# C·∫•u h√¨nh th∆∞ m·ª•c l∆∞u file t·∫°m
UPLOAD_FOLDER = 'temp'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# API ch·ªâ x·ª≠ l√Ω nh·∫≠n di·ªán bi·ªÉn s·ªë, kh√¥ng x·ª≠ l√Ω database
# T·ªëi ∆∞u h√≥a cho performance v√† memory

import threading
import queue
import gc

# Bi·∫øn global cho models
yolo_LP_detect = None
yolo_license_plate = None

# Kh·ªüi t·∫°o PlateMemoryManager v·ªõi ng∆∞·ª°ng similarity th·∫•p h∆°n cho API
plate_memory = PlateMemoryManager()
plate_memory.similarity_threshold = 0.2  # Lowered for better detection  # Gi·∫£m t·ª´ 0.6 xu·ªëng 0.5 ƒë·ªÉ tƒÉng kh·∫£ nƒÉng nh·∫≠n d·∫°ng cho camera real-time

# Queue ƒë·ªÉ x·ª≠ l√Ω request
request_queue = queue.Queue(maxsize=10)  # Gi·ªõi h·∫°n 10 request ƒë·ªìng th·ªùi
processing_lock = threading.Lock()

# Load models v·ªõi model t·ªëi ∆∞u h√≥a
def load_models():
    global yolo_LP_detect, yolo_license_plate
    print("Loading AI models...")

    # Set device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")

    yolo_LP_detect = torch.hub.load('yolov5', 'custom', path='model/LP_detector.pt',
                                   force_reload=True, source='local', trust_repo=True)
    yolo_license_plate = torch.hub.load('yolov5', 'custom', path='model/LP_ocr.pt',
                                       force_reload=True, source='local', trust_repo=True)

    # T·ªëi ∆∞u h√≥a models
    yolo_LP_detect.conf = 0.25  # Confidence threshold
    yolo_license_plate.conf = 0.60

    # Warm up models
    print("Warming up models...")
    dummy_img = torch.zeros((1, 3, 640, 640))
    with torch.no_grad():
        _ = yolo_LP_detect(dummy_img)

    print("‚úÖ Models loaded and optimized successfully!")

# Load models khi kh·ªüi ƒë·ªông
load_models()

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def base64_to_image(base64_string):
    """Chuy·ªÉn ƒë·ªïi base64 string th√†nh OpenCV image"""
    try:
        # Lo·∫°i b·ªè header data:image/jpeg;base64, n·∫øu c√≥
        if ',' in base64_string:
            base64_string = base64_string.split(',')[1]

        # Decode base64
        img_data = base64.b64decode(base64_string)

        # Chuy·ªÉn ƒë·ªïi th√†nh numpy array
        nparr = np.frombuffer(img_data, np.uint8)

        # Decode th√†nh OpenCV image
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        return img
    except Exception as e:
        print(f"L·ªói chuy·ªÉn ƒë·ªïi base64: {e}")
        return None

def normalize_plate_text(plate_text):
    """Chu·∫©n h√≥a format bi·ªÉn s·ªë ƒë·ªÉ so s√°nh t·ªët h∆°n"""
    if not plate_text:
        return ""

    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng v√† chuy·ªÉn v·ªÅ uppercase
    normalized = plate_text.strip().upper()

    # Th√™m d·∫•u g·∫°ch ngang n·∫øu ch∆∞a c√≥ (format chu·∫©n: XX-YYYY)
    if '-' not in normalized and len(normalized) >= 6:
        # T√¨m v·ªã tr√≠ s·ªë ƒë·∫ßu ti√™n
        for i, char in enumerate(normalized):
            if char.isdigit():
                if i > 0:  # C√≥ ch·ªØ c√°i tr∆∞·ªõc s·ªë
                    normalized = normalized[:i] + '-' + normalized[i:]
                break

    return normalized

def check_plate_memory(crop_img):
    """Ki·ªÉm tra plate memory ƒë·ªÉ t√¨m v√πng bi·ªÉn s·ªë t∆∞∆°ng t·ª± ƒë√£ ƒë∆∞·ª£c g√°n nh√£n"""
    try:
        similar_match = plate_memory.find_similar_plate(crop_img)
        if similar_match:
            plate_id, plate_text, similarity = similar_match
            # Chu·∫©n h√≥a plate text
            normalized_text = normalize_plate_text(plate_text)
            print(f"üéØ Plate Memory: T√¨m th·∫•y {normalized_text} (similarity: {similarity:.2f})")
            return {
                'found': True,
                'plate_text': normalized_text,
                'similarity': similarity,
                'plate_id': plate_id
            }
        return {'found': False}
    except Exception as e:
        print(f"L·ªói khi ki·ªÉm tra plate memory: {e}")
        return {'found': False}

def save_unrecognized_plate(crop_img, source_info="API"):
    """L∆∞u v√πng bi·ªÉn s·ªë kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c v√†o plate memory"""
    try:
        plate_id = plate_memory.save_unrecognized_plate(crop_img, source_info)
        return {
            'saved': True,
            'plate_id': plate_id
        }
    except Exception as e:
        print(f"L·ªói khi l∆∞u v√†o plate memory: {e}")
        return {'saved': False}

def detect_license_plate_from_image(img):
    """Nh·∫≠n di·ªán bi·ªÉn s·ªë t·ª´ OpenCV image - t·ªëi ∆∞u h√≥a memory v√† performance"""
    if img is None:
        return {
            'success': False,
            'message': '·∫¢nh kh√¥ng h·ª£p l·ªá',
            'plates': [],
            'confidence': 0,
            'processing_time': 0
        }

    start_time = time.time()

    try:
        with processing_lock:  # ƒê·∫£m b·∫£o ch·ªâ x·ª≠ l√Ω 1 request t·∫°i 1 th·ªùi ƒëi·ªÉm
            # C·∫£i thi·ªán ·∫£nh ch·∫•t l∆∞·ª£ng th·∫•p
            height, width = img.shape[:2]

            # N·∫øu ·∫£nh qu√° nh·ªè, upscale l√™n
            if width < 800 or height < 600:
                scale_factor = max(800/width, 600/height)
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                print(f"üìà Upscaled image: {width}x{height} ‚Üí {new_width}x{new_height}")

            # C·∫£i thi·ªán contrast v√† brightness cho ·∫£nh t·ªëi
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            img = cv2.merge([l, a, b])
            img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)

            # Ph√°t hi·ªán bi·ªÉn s·ªë v·ªõi torch.no_grad() ƒë·ªÉ ti·∫øt ki·ªám memory
            with torch.no_grad():
                plates = yolo_LP_detect(img, size=640)
                list_plates = plates.pandas().xyxy[0].values.tolist()

            list_read_plates = set()
            confidence_scores = []
            plate_memory_results = []  # L∆∞u k·∫øt qu·∫£ t·ª´ plate memory

            if len(list_plates) == 0:
                print("‚ö†Ô∏è  Kh√¥ng ph√°t hi·ªán bi·ªÉn s·ªë, th·ª≠ c√°c ph∆∞∆°ng ph√°p fallback...")

                # Fallback 1: Th·ª≠ ƒë·ªçc to√†n b·ªô ·∫£nh
                with torch.no_grad():
                    lp = helper.read_plate(yolo_license_plate, img)
                if lp != "unknown":
                    clean_plate = lp.strip().upper()
                    if len(clean_plate) >= 6:
                        list_read_plates.add(clean_plate)
                        confidence_scores.append(50)
                        print(f"üîÑ Fallback OCR to√†n ·∫£nh: {clean_plate}")

                # Fallback 2: Th·ª≠ v·ªõi YOLO threshold th·∫•p h∆°n
                if len(list_read_plates) == 0:
                    with torch.no_grad():
                        plates_low = yolo_LP_detect(img, size=640)
                        # L·ªçc v·ªõi confidence th·∫•p h∆°n (0.3 thay v√¨ 0.5)
                        list_plates_low = plates_low.pandas().xyxy[0]
                        list_plates_low = list_plates_low[list_plates_low['confidence'] > 0.3].values.tolist()

                    if len(list_plates_low) > 0:
                        print(f"üîÑ Fallback v·ªõi threshold th·∫•p: t√¨m th·∫•y {len(list_plates_low)} v√πng")
                        list_plates = list_plates_low  # S·ª≠ d·ª•ng k·∫øt qu·∫£ threshold th·∫•p
            else:
                for plate in list_plates:
                    x = int(plate[0])
                    y = int(plate[1])
                    w = int(plate[2] - plate[0])
                    h = int(plate[3] - plate[1])

                    # Ki·ªÉm tra k√≠ch th∆∞·ªõc crop h·ª£p l·ªá
                    if w > 10 and h > 10:
                        crop_img = img[y:y+h, x:x+w]
                        plate_confidence = float(plate[4]) * 100  # Confidence t·ª´ YOLO detection

                        # ‚ú® ∆ØU TI√äN PLATE MEMORY TR∆Ø·ªöC - Ki·ªÉm tra plate memory ƒë·∫ßu ti√™n
                        found = False
                        memory_result = check_plate_memory(crop_img)

                        if memory_result['found']:
                            # üéØ T√¨m th·∫•y trong plate memory - ∆∞u ti√™n cao nh·∫•t
                            plate_text = memory_result['plate_text']
                            similarity = memory_result['similarity']
                            list_read_plates.add(plate_text)
                            # Confidence cao cho plate memory (similarity * 100 + bonus)
                            memory_confidence = min(similarity * 100 + 10, 100)  # Bonus 10 ƒëi·ªÉm, max 100
                            confidence_scores.append(memory_confidence)
                            plate_memory_results.append({
                                'plate_text': plate_text,
                                'similarity': similarity,
                                'plate_id': memory_result['plate_id'][:8],
                                'source': 'plate_memory',
                                'priority': 'high'  # ƒê√°nh d·∫•u ∆∞u ti√™n cao
                            })
                            found = True
                            print(f"üéØ API: ∆Øu ti√™n t·ª´ plate memory: {plate_text} (similarity: {similarity:.2f}, confidence: {memory_confidence:.1f})")

                        # N·∫øu kh√¥ng t√¨m th·∫•y trong memory, m·ªõi th·ª≠ OCR
                        if not found:
                            for cc in range(0, 2):
                                if found:
                                    break
                                for ct in range(0, 2):
                                    with torch.no_grad():
                                        lp = helper.read_plate(yolo_license_plate, utils_rotate.deskew(crop_img, cc, ct))
                                    if lp != "unknown":
                                        clean_plate = lp.strip().upper()
                                        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng bi·ªÉn s·ªë Vi·ªát Nam c∆° b·∫£n
                                        if len(clean_plate) >= 6:
                                            list_read_plates.add(clean_plate)
                                            confidence_scores.append(plate_confidence)
                                            found = True
                                            print(f"ü§ñ API: OCR nh·∫≠n d·∫°ng: {clean_plate} (confidence: {plate_confidence:.1f})")
                                            break

            processing_time = time.time() - start_time

            # ‚ú® S·∫Øp x·∫øp k·∫øt qu·∫£ ∆∞u ti√™n plate memory tr∆∞·ªõc
            result_plates = list(list_read_plates)

            # S·∫Øp x·∫øp theo ∆∞u ti√™n: plate memory tr∆∞·ªõc, OCR sau
            if plate_memory_results:
                # T√°ch bi·ªÉn s·ªë t·ª´ memory v√† OCR
                memory_plates = [r['plate_text'] for r in plate_memory_results]
                ocr_plates = [p for p in result_plates if p not in memory_plates]

                # S·∫Øp x·∫øp l·∫°i: memory tr∆∞·ªõc, OCR sau
                result_plates = memory_plates + ocr_plates

                # T√≠nh confidence ∆∞u ti√™n memory
                memory_confidences = [min(r['similarity'] * 100 + 10, 100) for r in plate_memory_results]
                ocr_confidences = [c for i, c in enumerate(confidence_scores) if i >= len(memory_confidences)]
                confidence_scores = memory_confidences + ocr_confidences

            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0

            # D·ªçn d·∫πp memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()

            # T·∫°o th√¥ng b√°o chi ti·∫øt v·ªõi ∆∞u ti√™n
            message_parts = []
            if result_plates:
                memory_count = len(plate_memory_results)
                ocr_count = len(result_plates) - memory_count

                # ∆Øu ti√™n hi·ªÉn th·ªã memory tr∆∞·ªõc
                if memory_count > 0:
                    message_parts.append(f"üéØ Memory: {memory_count} bi·ªÉn s·ªë (∆∞u ti√™n)")
                if ocr_count > 0:
                    message_parts.append(f"ü§ñ OCR: {ocr_count} bi·ªÉn s·ªë")

                if memory_count > 0:
                    message = f"‚úÖ Ph√°t hi·ªán {len(result_plates)} bi·ªÉn s·ªë - ∆Øu ti√™n t·ª´ Plate Memory ({', '.join(message_parts)})"
                else:
                    message = f"Ph√°t hi·ªán {len(result_plates)} bi·ªÉn s·ªë ({', '.join(message_parts)})"
            else:
                message = 'Kh√¥ng ph√°t hi·ªán bi·ªÉn s·ªë'

            return {
                'success': True,
                'plates': result_plates,
                'confidence': round(avg_confidence, 2),
                'processing_time': round(processing_time, 3),
                'detected_boxes': len(list_plates),
                'message': message,
                'plate_memory_results': plate_memory_results,  # Th√¥ng tin t·ª´ plate memory
                'detection_methods': {
                    'ocr_count': len(result_plates) - len(plate_memory_results),
                    'memory_count': len(plate_memory_results),
                    'total_count': len(result_plates)
                }
            }

    except Exception as e:
        processing_time = time.time() - start_time
        # D·ªçn d·∫πp memory khi c√≥ l·ªói
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

        return {
            'success': False,
            'message': f'L·ªói x·ª≠ l√Ω: {str(e)}',
            'plates': [],
            'confidence': 0,
            'processing_time': round(processing_time, 3),
            'detected_boxes': 0
        }

def detect_license_plate(image_path):
    """Nh·∫≠n di·ªán bi·ªÉn s·ªë t·ª´ file path (backward compatibility)"""
    img = cv2.imread(image_path)
    result = detect_license_plate_from_image(img)
    return result

@app.route('/detect', methods=['POST'])
def detect():
    """Endpoint nh·∫≠n di·ªán bi·ªÉn s·ªë t·ª´ file upload"""
    try:
        if 'image' not in request.files:
            return jsonify({'success': False, 'message': 'Kh√¥ng t√¨m th·∫•y file ·∫£nh'})

        image_file = request.files['image']
        if image_file.filename == '':
            return jsonify({'success': False, 'message': 'Ch∆∞a ch·ªçn file ·∫£nh'})

        if not allowed_file(image_file.filename):
            return jsonify({'success': False, 'message': 'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£'})

        filename = secure_filename(image_file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        image_file.save(filepath)

        try:
            img = cv2.imread(filepath)
            result = detect_license_plate_from_image(img)

            # Tr·∫£ v·ªÅ k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß
            return jsonify(result)

        finally:
            # X√≥a file t·∫°m
            if os.path.exists(filepath):
                os.remove(filepath)

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói server: {str(e)}',
            'plates': [],
            'confidence': 0,
            'processing_time': 0
        })

@app.route('/detect_base64', methods=['POST'])
def detect_base64():
    """Endpoint nh·∫≠n di·ªán bi·ªÉn s·ªë t·ª´ base64 image - t·ªëi ∆∞u cho real-time"""
    try:
        data = request.get_json()

        if not data or 'image' not in data:
            return jsonify({
                'success': False,
                'message': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh base64',
                'plates': [],
                'confidence': 0
            })

        base64_image = data['image']
        camera_type = data.get('type', 'unknown')  # 'entry' ho·∫∑c 'exit'

        # Chuy·ªÉn ƒë·ªïi base64 th√†nh OpenCV image
        img = base64_to_image(base64_image)
        if img is None:
            return jsonify({
                'success': False,
                'message': 'Kh√¥ng th·ªÉ decode ·∫£nh base64',
                'plates': [],
                'confidence': 0
            })

        # Nh·∫≠n di·ªán bi·ªÉn s·ªë
        result = detect_license_plate_from_image(img)

        # Th√™m th√¥ng tin b·ªï sung
        result['camera_type'] = camera_type
        result['timestamp'] = int(time.time())
        result['detection_details'] = {
            'total_plates_found': len(result['plates']) if result['plates'] else 0,
            'best_confidence': result['confidence'],
            'detection_method': 'YOLOv5 + OCR',
            'image_processed': True
        }

        # X√°c ƒë·ªãnh tr·∫°ng th√°i v√† th√™m th√¥ng tin chi ti·∫øt v·ªõi ∆∞u ti√™n plate memory
        if result['success'] and result['plates']:
            result['plate'] = result['plates'][0]  # L·∫•y bi·ªÉn s·ªë ƒë·∫ßu ti√™n (ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp ∆∞u ti√™n)

            # Ki·ªÉm tra xem c√≥ t·ª´ plate memory kh√¥ng
            has_memory_result = result.get('plate_memory_results') and len(result['plate_memory_results']) > 0

            if has_memory_result:
                # ∆Øu ti√™n cao cho plate memory
                memory_info = result['plate_memory_results'][0]
                result['status'] = 'detected_memory'
                result['status_message'] = f'üéØ Nh·∫≠n di·ªán t·ª´ Plate Memory: {result["plate"]} (similarity: {memory_info["similarity"]:.2f}, ∆∞u ti√™n cao)'
                result['detection_source'] = 'plate_memory'
                result['priority'] = 'high'
            elif result['confidence'] > 60:
                result['status'] = 'detected'
                result['status_message'] = f'ü§ñ OCR nh·∫≠n di·ªán: {result["plate"]} (ƒê·ªô tin c·∫≠y: {result["confidence"]:.1f}%)'
                result['detection_source'] = 'ocr'
                result['priority'] = 'normal'
            else:
                result['status'] = 'low_confidence'
                result['status_message'] = f'‚ö†Ô∏è  Ph√°t hi·ªán bi·ªÉn s·ªë: {result["plate"]} nh∆∞ng ƒë·ªô tin c·∫≠y th·∫•p ({result["confidence"]:.1f}%)'
                result['detection_source'] = 'ocr'
                result['priority'] = 'low'
        else:
            result['status'] = 'no_plate'
            result['status_message'] = 'Kh√¥ng ph√°t hi·ªán bi·ªÉn s·ªë trong ·∫£nh'
            result['detection_source'] = 'none'
            result['priority'] = 'none'

        # Log k·∫øt qu·∫£ chi ti·∫øt ƒë·ªÉ debug
        print(f"üéØ [{camera_type.upper()}] {result['status_message']} - Time: {result['processing_time']:.2f}s")
        if result['success'] and result['plates']:
            print(f"üìã Detected plates: {result['plates']}")
            if result.get('plate_memory_results'):
                print(f"üß† Memory results: {[r['plate_text'] for r in result['plate_memory_results']]}")
        else:
            print(f"‚ùå No plates detected in {camera_type} camera")

        return jsonify(result)

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói server: {str(e)}',
            'plates': [],
            'confidence': 0,
            'processing_time': 0,
            'status': 'error'
        })

@app.route('/health', methods=['GET'])
def health_check():
    """Ki·ªÉm tra tr·∫°ng th√°i API"""
    return jsonify({
        'status': 'ok',
        'message': 'API nh·∫≠n di·ªán bi·ªÉn s·ªë ƒëang ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng',
        'models_loaded': True,
        'version': '1.0.0',
        'endpoints': {
            'POST /detect': 'Nh·∫≠n d·∫°ng bi·ªÉn s·ªë t·ª´ file ·∫£nh upload',
            'POST /detect_base64': 'Nh·∫≠n d·∫°ng bi·ªÉn s·ªë t·ª´ base64 (real-time)',
            'GET /health': 'Ki·ªÉm tra tr·∫°ng th√°i API',
            'GET /info': 'Th√¥ng tin chi ti·∫øt v·ªÅ API'
        }
    }), 200

@app.route('/info', methods=['GET'])
def get_info():
    """Th√¥ng tin chi ti·∫øt v·ªÅ API"""
    return jsonify({
        'api_name': 'License Plate Recognition API',
        'version': '2.0.0',
        'description': 'API nh·∫≠n di·ªán bi·ªÉn s·ªë xe Vi·ªát Nam v·ªõi ∆∞u ti√™n Plate Memory',
        'models': {
            'detector': 'LP_detector.pt',
            'ocr': 'LP_ocr.pt',
            'confidence_threshold': 0.60,
            'plate_memory_threshold': 0.5
        },
        'features': [
            'üéØ ∆ØU TI√äN Plate Memory - Nh·∫≠n d·∫°ng bi·ªÉn s·ªë ƒë√£ g√°n nh√£n tr∆∞·ªõc',
            'ü§ñ OCR fallback - S·ª≠ d·ª•ng OCR khi kh√¥ng t√¨m th·∫•y trong memory',
            'üì∏ Nh·∫≠n di·ªán t·ª´ file ·∫£nh upload',
            '‚ö° Real-time t·ª´ base64 (camera, webcam)',
            'üß† T·ª± ƒë·ªông h·ªçc v√† ghi nh·ªõ bi·ªÉn s·ªë m·ªõi',
            'üöÄ T·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô x·ª≠ l√Ω',
            'üåê H·ªó tr·ª£ CORS cho web integration',
            'üìä API qu·∫£n l√Ω Plate Memory'
        ],
        'response_format': {
            'success': 'boolean - Tr·∫°ng th√°i x·ª≠ l√Ω',
            'plates': 'array - Danh s√°ch bi·ªÉn s·ªë ph√°t hi·ªán',
            'confidence': 'number - ƒê·ªô tin c·∫≠y (0-100)',
            'processing_time': 'number - Th·ªùi gian x·ª≠ l√Ω (gi√¢y)',
            'message': 'string - Th√¥ng b√°o k·∫øt qu·∫£',
            'plate_memory_results': 'array - K·∫øt qu·∫£ t·ª´ plate memory',
            'detection_methods': 'object - Th·ªëng k√™ ph∆∞∆°ng ph√°p nh·∫≠n d·∫°ng'
        }
    })

@app.route('/plate_memory/stats', methods=['GET'])
def get_plate_memory_stats():
    """L·∫•y th·ªëng k√™ plate memory"""
    try:
        stats = plate_memory.get_statistics()
        return jsonify({
            'success': True,
            'stats': stats,
            'message': 'Th·ªëng k√™ plate memory'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói khi l·∫•y th·ªëng k√™: {str(e)}'
        })

@app.route('/plate_memory/labeled', methods=['GET'])
def get_labeled_plates():
    """L·∫•y danh s√°ch bi·ªÉn s·ªë ƒë√£ g√°n nh√£n"""
    try:
        labeled_plates = plate_memory.get_labeled_plates()
        return jsonify({
            'success': True,
            'labeled_plates': labeled_plates,
            'count': len(labeled_plates),
            'message': f'T√¨m th·∫•y {len(labeled_plates)} bi·ªÉn s·ªë ƒë√£ g√°n nh√£n'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói khi l·∫•y danh s√°ch: {str(e)}'
        })

@app.route('/plate_memory/assign', methods=['POST'])
def assign_plate_label():
    """G√°n nh√£n cho bi·ªÉn s·ªë"""
    try:
        data = request.get_json()

        if not data or 'plate_id' not in data or 'plate_text' not in data:
            return jsonify({
                'success': False,
                'message': 'Thi·∫øu th√¥ng tin plate_id ho·∫∑c plate_text'
            })

        plate_id = data['plate_id']
        plate_text = data['plate_text']

        success = plate_memory.assign_plate_text(plate_id, plate_text)

        if success:
            return jsonify({
                'success': True,
                'message': f'ƒê√£ g√°n nh√£n "{plate_text}" cho plate_id: {plate_id[:8]}...'
            })
        else:
            return jsonify({
                'success': False,
                'message': f'Kh√¥ng th·ªÉ g√°n nh√£n cho plate_id: {plate_id}'
            })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói khi g√°n nh√£n: {str(e)}'
        })

@app.route('/debug/save_camera_image', methods=['POST'])
def save_camera_image():
    """Debug endpoint - L∆∞u ·∫£nh t·ª´ camera ƒë·ªÉ ki·ªÉm tra"""
    try:
        data = request.get_json()

        if not data or 'image' not in data:
            return jsonify({
                'success': False,
                'message': 'Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ·∫£nh base64'
            })

        base64_image = data['image']
        camera_type = data.get('type', 'unknown')

        # Chuy·ªÉn ƒë·ªïi base64 th√†nh OpenCV image
        img = base64_to_image(base64_image)
        if img is None:
            return jsonify({
                'success': False,
                'message': 'Kh√¥ng th·ªÉ decode ·∫£nh base64'
            })

        # L∆∞u ·∫£nh ƒë·ªÉ debug
        import os
        debug_dir = "debug_images"
        if not os.path.exists(debug_dir):
            os.makedirs(debug_dir)

        timestamp = int(time.time())
        filename = f"{debug_dir}/camera_{camera_type}_{timestamp}.jpg"
        cv2.imwrite(filename, img)

        # Th·ª≠ nh·∫≠n d·∫°ng
        result = detect_license_plate_from_image(img)

        return jsonify({
            'success': True,
            'message': f'ƒê√£ l∆∞u ·∫£nh debug: {filename}',
            'image_saved': filename,
            'detection_result': result,
            'image_size': f"{img.shape[1]}x{img.shape[0]}"
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'L·ªói debug: {str(e)}'
        })

if __name__ == '__main__':
    try:
        print("=" * 60)
        print("üöó LICENSE PLATE RECOGNITION API SERVER v2.0")
        print("=" * 60)
        print("üéØ Ch·ª©c nƒÉng: ∆ØU TI√äN Plate Memory + OCR Fallback")
        print("ü§ñ AI Models: YOLOv5 Full (t∆∞∆°ng th√≠ch plate memory)")
        print("üß† Plate Memory: Nh·∫≠n d·∫°ng bi·ªÉn s·ªë ƒë√£ g√°n nh√£n TR∆Ø·ªöC")
        print("‚ö° OCR: S·ª≠ d·ª•ng khi kh√¥ng t√¨m th·∫•y trong memory")
        print("‚úÖ Models loaded successfully!")

        # Hi·ªÉn th·ªã th·ªëng k√™ plate memory
        try:
            stats = plate_memory.get_statistics()
            print(f"üìä Plate Memory: {stats['labeled_plates']}/{stats['total_plates']} ƒë√£ g√°n nh√£n")
        except:
            print("üìä Plate Memory: ƒê√£ kh·ªüi t·∫°o")

        print("\nüì° Available endpoints:")
        print("  üî∏ POST /detect              - Nh·∫≠n d·∫°ng t·ª´ file ·∫£nh upload")
        print("  üî∏ POST /detect_base64       - Nh·∫≠n d·∫°ng t·ª´ base64 (real-time)")
        print("  üî∏ GET  /health              - Ki·ªÉm tra tr·∫°ng th√°i API")
        print("  üî∏ GET  /info                - Th√¥ng tin chi ti·∫øt API")
        print("  üî∏ GET  /plate_memory/stats  - Th·ªëng k√™ plate memory")
        print("  üî∏ GET  /plate_memory/labeled - Danh s√°ch bi·ªÉn s·ªë ƒë√£ g√°n nh√£n")
        print("  üî∏ POST /plate_memory/assign - G√°n nh√£n cho bi·ªÉn s·ªë")
        print("\nüåê Server URL: http://localhost:5000")
        print("üîß Mode: Production (threaded=True)")
        print("=" * 60)

        app.run(debug=False, host='0.0.0.0', port=5000, threaded=True)

    except Exception as e:
        print(f"‚ùå Error starting server: {e}")
        print("üí° Ki·ªÉm tra:")
        print("   - Port 5000 c√≥ ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng?")
        print("   - C√°c file model c√≥ t·ªìn t·∫°i?")
        print("   - Dependencies ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t ƒë·∫ßy ƒë·ªß?")
