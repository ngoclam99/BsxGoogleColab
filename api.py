from flask import Flask, request, jsonify
import cv2
import torch
import function.utils_rotate as utils_rotate
import function.helper as helper
import os
import base64
import numpy as np
import time
from werkzeug.utils import secure_filename
from flask_cors import CORS
from plate_memory import PlateMemoryManager

app = Flask(__name__)
CORS(app, resources={
    r"/*": {
        "origins": "*",
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})

# Cáº¥u hÃ¬nh thÆ° má»¥c lÆ°u file táº¡m
UPLOAD_FOLDER = 'temp'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# API chá»‰ xá»­ lÃ½ nháº­n diá»‡n biá»ƒn sá»‘, khÃ´ng xá»­ lÃ½ database
# Tá»‘i Æ°u hÃ³a cho performance vÃ  memory

import threading
import queue
import gc

# Biáº¿n global cho models
yolo_LP_detect = None
yolo_license_plate = None

# Khá»Ÿi táº¡o PlateMemoryManager vá»›i ngÆ°á»¡ng similarity tháº¥p hÆ¡n cho API
plate_memory = PlateMemoryManager()
plate_memory.similarity_threshold = 0.2  # Lowered for better detection  # Giáº£m tá»« 0.6 xuá»‘ng 0.5 Ä‘á»ƒ tÄƒng kháº£ nÄƒng nháº­n dáº¡ng cho camera real-time

# Queue Ä‘á»ƒ xá»­ lÃ½ request
request_queue = queue.Queue(maxsize=10)  # Giá»›i háº¡n 10 request Ä‘á»“ng thá»i
processing_lock = threading.Lock()

# Load models vá»›i model tá»‘i Æ°u hÃ³a
def load_models():
    global yolo_LP_detect, yolo_license_plate
    print("Loading AI models...")

    # Set device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")

    yolo_LP_detect = torch.hub.load('yolov5', 'custom', path='model/LP_detector.pt',
                                   force_reload=True, source='local', trust_repo=True)
    yolo_license_plate = torch.hub.load('yolov5', 'custom', path='model/LP_ocr.pt',
                                       force_reload=True, source='local', trust_repo=True)

    # Tá»‘i Æ°u hÃ³a models
    yolo_LP_detect.conf = 0.25  # Confidence threshold
    yolo_license_plate.conf = 0.60

    # Warm up models
    print("Warming up models...")
    dummy_img = torch.zeros((1, 3, 640, 640))
    with torch.no_grad():
        _ = yolo_LP_detect(dummy_img)

    print("âœ… Models loaded and optimized successfully!")

# Load models khi khá»Ÿi Ä‘á»™ng
load_models()

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def base64_to_image(base64_string):
    """Chuyá»ƒn Ä‘á»•i base64 string thÃ nh OpenCV image"""
    try:
        # Loáº¡i bá» header data:image/jpeg;base64, náº¿u cÃ³
        if ',' in base64_string:
            base64_string = base64_string.split(',')[1]

        # Decode base64
        img_data = base64.b64decode(base64_string)

        # Chuyá»ƒn Ä‘á»•i thÃ nh numpy array
        nparr = np.frombuffer(img_data, np.uint8)

        # Decode thÃ nh OpenCV image
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        return img
    except Exception as e:
        print(f"Lá»—i chuyá»ƒn Ä‘á»•i base64: {e}")
        return None

def normalize_plate_text(plate_text):
    """Chuáº©n hÃ³a format biá»ƒn sá»‘ Ä‘á»ƒ so sÃ¡nh tá»‘t hÆ¡n"""
    if not plate_text:
        return ""

    # Loáº¡i bá» khoáº£ng tráº¯ng vÃ  chuyá»ƒn vá» uppercase
    normalized = plate_text.strip().upper()

    # ThÃªm dáº¥u gáº¡ch ngang náº¿u chÆ°a cÃ³ (format chuáº©n: XX-YYYY)
    if '-' not in normalized and len(normalized) >= 6:
        # TÃ¬m vá»‹ trÃ­ sá»‘ Ä‘áº§u tiÃªn
        for i, char in enumerate(normalized):
            if char.isdigit():
                if i > 0:  # CÃ³ chá»¯ cÃ¡i trÆ°á»›c sá»‘
                    normalized = normalized[:i] + '-' + normalized[i:]
                break

    return normalized

def check_plate_memory(crop_img):
    """Kiá»ƒm tra plate memory Ä‘á»ƒ tÃ¬m vÃ¹ng biá»ƒn sá»‘ tÆ°Æ¡ng tá»± Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n"""
    try:
        similar_match = plate_memory.find_similar_plate(crop_img)
        if similar_match:
            plate_id, plate_text, similarity = similar_match
            # Chuáº©n hÃ³a plate text
            normalized_text = normalize_plate_text(plate_text)
            print(f"ğŸ¯ Plate Memory: TÃ¬m tháº¥y {normalized_text} (similarity: {similarity:.2f})")
            return {
                'found': True,
                'plate_text': normalized_text,
                'similarity': similarity,
                'plate_id': plate_id
            }
        return {'found': False}
    except Exception as e:
        print(f"Lá»—i khi kiá»ƒm tra plate memory: {e}")
        return {'found': False}

def save_unrecognized_plate(crop_img, source_info="API"):
    """LÆ°u vÃ¹ng biá»ƒn sá»‘ khÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c vÃ o plate memory"""
    try:
        plate_id = plate_memory.save_unrecognized_plate(crop_img, source_info)
        return {
            'saved': True,
            'plate_id': plate_id
        }
    except Exception as e:
        print(f"Lá»—i khi lÆ°u vÃ o plate memory: {e}")
        return {'saved': False}

def detect_license_plate_from_image(img):
    """Nháº­n diá»‡n biá»ƒn sá»‘ tá»« OpenCV image - tá»‘i Æ°u hÃ³a memory vÃ  performance"""
    if img is None:
        return {
            'success': False,
            'message': 'áº¢nh khÃ´ng há»£p lá»‡',
            'plates': [],
            'confidence': 0,
            'processing_time': 0
        }

    start_time = time.time()

    try:
        with processing_lock:  # Äáº£m báº£o chá»‰ xá»­ lÃ½ 1 request táº¡i 1 thá»i Ä‘iá»ƒm
            # Cáº£i thiá»‡n áº£nh cháº¥t lÆ°á»£ng tháº¥p
            height, width = img.shape[:2]

            # Náº¿u áº£nh quÃ¡ nhá», upscale lÃªn
            if width < 800 or height < 600:
                scale_factor = max(800/width, 600/height)
                new_width = int(width * scale_factor)
                new_height = int(height * scale_factor)
                img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                print(f"ğŸ“ˆ Upscaled image: {width}x{height} â†’ {new_width}x{new_height}")

            # Cáº£i thiá»‡n contrast vÃ  brightness cho áº£nh tá»‘i
            lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            l = clahe.apply(l)
            img = cv2.merge([l, a, b])
            img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)

            # PhÃ¡t hiá»‡n biá»ƒn sá»‘ vá»›i torch.no_grad() Ä‘á»ƒ tiáº¿t kiá»‡m memory
            with torch.no_grad():
                plates = yolo_LP_detect(img, size=640)
                list_plates = plates.pandas().xyxy[0].values.tolist()

            list_read_plates = set()
            confidence_scores = []
            plate_memory_results = []  # LÆ°u káº¿t quáº£ tá»« plate memory

            if len(list_plates) == 0:
                print("âš ï¸  KhÃ´ng phÃ¡t hiá»‡n biá»ƒn sá»‘, thá»­ cÃ¡c phÆ°Æ¡ng phÃ¡p fallback...")

                # Fallback 1: Thá»­ Ä‘á»c toÃ n bá»™ áº£nh
                with torch.no_grad():
                    lp = helper.read_plate(yolo_license_plate, img)
                if lp != "unknown":
                    clean_plate = lp.strip().upper()
                    if len(clean_plate) >= 6:
                        list_read_plates.add(clean_plate)
                        confidence_scores.append(50)
                        print(f"ğŸ”„ Fallback OCR toÃ n áº£nh: {clean_plate}")

                # Fallback 2: Thá»­ vá»›i YOLO threshold tháº¥p hÆ¡n
                if len(list_read_plates) == 0:
                    with torch.no_grad():
                        plates_low = yolo_LP_detect(img, size=640)
                        # Lá»c vá»›i confidence tháº¥p hÆ¡n (0.3 thay vÃ¬ 0.5)
                        list_plates_low = plates_low.pandas().xyxy[0]
                        list_plates_low = list_plates_low[list_plates_low['confidence'] > 0.3].values.tolist()

                    if len(list_plates_low) > 0:
                        print(f"ğŸ”„ Fallback vá»›i threshold tháº¥p: tÃ¬m tháº¥y {len(list_plates_low)} vÃ¹ng")
                        list_plates = list_plates_low  # Sá»­ dá»¥ng káº¿t quáº£ threshold tháº¥p
            else:
                for plate in list_plates:
                    x = int(plate[0])
                    y = int(plate[1])
                    w = int(plate[2] - plate[0])
                    h = int(plate[3] - plate[1])

                    # Kiá»ƒm tra kÃ­ch thÆ°á»›c crop há»£p lá»‡
                    if w > 10 and h > 10:
                        crop_img = img[y:y+h, x:x+w]
                        plate_confidence = float(plate[4]) * 100  # Confidence tá»« YOLO detection

                        # âœ¨ Æ¯U TIÃŠN PLATE MEMORY TRÆ¯á»šC - Kiá»ƒm tra plate memory Ä‘áº§u tiÃªn
                        found = False
                        memory_result = check_plate_memory(crop_img)

                        if memory_result['found']:
                            # ğŸ¯ TÃ¬m tháº¥y trong plate memory - Æ°u tiÃªn cao nháº¥t
                            plate_text = memory_result['plate_text']
                            similarity = memory_result['similarity']
                            list_read_plates.add(plate_text)
                            # Confidence cao cho plate memory (similarity * 100 + bonus)
                            memory_confidence = min(similarity * 100 + 10, 100)  # Bonus 10 Ä‘iá»ƒm, max 100
                            confidence_scores.append(memory_confidence)
                            plate_memory_results.append({
                                'plate_text': plate_text,
                                'similarity': similarity,
                                'plate_id': memory_result['plate_id'][:8],
                                'source': 'plate_memory',
                                'priority': 'high'  # ÄÃ¡nh dáº¥u Æ°u tiÃªn cao
                            })
                            found = True
                            print(f"ğŸ¯ API: Æ¯u tiÃªn tá»« plate memory: {plate_text} (similarity: {similarity:.2f}, confidence: {memory_confidence:.1f})")

                        # Náº¿u khÃ´ng tÃ¬m tháº¥y trong memory, má»›i thá»­ OCR
                        if not found:
                            for cc in range(0, 2):
                                if found:
                                    break
                                for ct in range(0, 2):
                                    with torch.no_grad():
                                        lp = helper.read_plate(yolo_license_plate, utils_rotate.deskew(crop_img, cc, ct))
                                    if lp != "unknown":
                                        clean_plate = lp.strip().upper()
                                        # Kiá»ƒm tra Ä‘á»‹nh dáº¡ng biá»ƒn sá»‘ Viá»‡t Nam cÆ¡ báº£n
                                        if len(clean_plate) >= 6:
                                            list_read_plates.add(clean_plate)
                                            confidence_scores.append(plate_confidence)
                                            found = True
                                            print(f"ğŸ¤– API: OCR nháº­n dáº¡ng: {clean_plate} (confidence: {plate_confidence:.1f})")
                                            break

            processing_time = time.time() - start_time

            # âœ¨ Sáº¯p xáº¿p káº¿t quáº£ Æ°u tiÃªn plate memory trÆ°á»›c
            result_plates = list(list_read_plates)

            # Sáº¯p xáº¿p theo Æ°u tiÃªn: plate memory trÆ°á»›c, OCR sau
            if plate_memory_results:
                # TÃ¡ch biá»ƒn sá»‘ tá»« memory vÃ  OCR
                memory_plates = [r['plate_text'] for r in plate_memory_results]
                ocr_plates = [p for p in result_plates if p not in memory_plates]

                # Sáº¯p xáº¿p láº¡i: memory trÆ°á»›c, OCR sau
                result_plates = memory_plates + ocr_plates

                # TÃ­nh confidence Æ°u tiÃªn memory
                memory_confidences = [min(r['similarity'] * 100 + 10, 100) for r in plate_memory_results]
                ocr_confidences = [c for i, c in enumerate(confidence_scores) if i >= len(memory_confidences)]
                confidence_scores = memory_confidences + ocr_confidences

            avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0

            # Dá»n dáº¹p memory
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()

            # Táº¡o thÃ´ng bÃ¡o chi tiáº¿t vá»›i Æ°u tiÃªn
            message_parts = []
            if result_plates:
                memory_count = len(plate_memory_results)
                ocr_count = len(result_plates) - memory_count

                # Æ¯u tiÃªn hiá»ƒn thá»‹ memory trÆ°á»›c
                if memory_count > 0:
                    message_parts.append(f"ğŸ¯ Memory: {memory_count} biá»ƒn sá»‘ (Æ°u tiÃªn)")
                if ocr_count > 0:
                    message_parts.append(f"ğŸ¤– OCR: {ocr_count} biá»ƒn sá»‘")

                if memory_count > 0:
                    message = f"âœ… PhÃ¡t hiá»‡n {len(result_plates)} biá»ƒn sá»‘ - Æ¯u tiÃªn tá»« Plate Memory ({', '.join(message_parts)})"
                else:
                    message = f"PhÃ¡t hiá»‡n {len(result_plates)} biá»ƒn sá»‘ ({', '.join(message_parts)})"
            else:
                message = 'KhÃ´ng phÃ¡t hiá»‡n biá»ƒn sá»‘'

            return {
                'success': True,
                'plates': result_plates,
                'confidence': round(avg_confidence, 2),
                'processing_time': round(processing_time, 3),
                'detected_boxes': len(list_plates),
                'message': message,
                'plate_memory_results': plate_memory_results,  # ThÃ´ng tin tá»« plate memory
                'detection_methods': {
                    'ocr_count': len(result_plates) - len(plate_memory_results),
                    'memory_count': len(plate_memory_results),
                    'total_count': len(result_plates)
                }
            }

    except Exception as e:
        processing_time = time.time() - start_time
        # Dá»n dáº¹p memory khi cÃ³ lá»—i
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

        return {
            'success': False,
            'message': f'Lá»—i xá»­ lÃ½: {str(e)}',
            'plates': [],
            'confidence': 0,
            'processing_time': round(processing_time, 3),
            'detected_boxes': 0
        }

def detect_license_plate(image_path):
    """Nháº­n diá»‡n biá»ƒn sá»‘ tá»« file path (backward compatibility)"""
    img = cv2.imread(image_path)
    result = detect_license_plate_from_image(img)
    return result

@app.route('/detect', methods=['POST'])
def detect():
    """Endpoint nháº­n diá»‡n biá»ƒn sá»‘ tá»« file upload"""
    try:
        if 'image' not in request.files:
            return jsonify({'success': False, 'message': 'KhÃ´ng tÃ¬m tháº¥y file áº£nh'})

        image_file = request.files['image']
        if image_file.filename == '':
            return jsonify({'success': False, 'message': 'ChÆ°a chá»n file áº£nh'})

        if not allowed_file(image_file.filename):
            return jsonify({'success': False, 'message': 'Äá»‹nh dáº¡ng file khÃ´ng Ä‘Æ°á»£c há»— trá»£'})

        filename = secure_filename(image_file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        image_file.save(filepath)

        try:
            img = cv2.imread(filepath)
            result = detect_license_plate_from_image(img)

            # Tráº£ vá» káº¿t quáº£ Ä‘áº§y Ä‘á»§
            return jsonify(result)

        finally:
            # XÃ³a file táº¡m
            if os.path.exists(filepath):
                os.remove(filepath)

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Lá»—i server: {str(e)}',
            'plates': [],
            'confidence': 0,
            'processing_time': 0
        })

@app.route('/detect_base64', methods=['POST'])
def detect_base64():
    """Endpoint nháº­n diá»‡n biá»ƒn sá»‘ tá»« base64 image - tá»‘i Æ°u cho real-time"""
    try:
        data = request.get_json()

        if not data or 'image' not in data:
            return jsonify({
                'success': False,
                'message': 'KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u áº£nh base64',
                'plates': [],
                'confidence': 0
            })

        base64_image = data['image']
        camera_type = data.get('type', 'unknown')  # 'entry' hoáº·c 'exit'

        # Chuyá»ƒn Ä‘á»•i base64 thÃ nh OpenCV image
        img = base64_to_image(base64_image)
        if img is None:
            return jsonify({
                'success': False,
                'message': 'KhÃ´ng thá»ƒ decode áº£nh base64',
                'plates': [],
                'confidence': 0
            })

        # Nháº­n diá»‡n biá»ƒn sá»‘
        result = detect_license_plate_from_image(img)

        # ThÃªm thÃ´ng tin bá»• sung
        result['camera_type'] = camera_type
        result['timestamp'] = int(time.time())
        result['detection_details'] = {
            'total_plates_found': len(result['plates']) if result['plates'] else 0,
            'best_confidence': result['confidence'],
            'detection_method': 'YOLOv5 + OCR',
            'image_processed': True
        }

        # XÃ¡c Ä‘á»‹nh tráº¡ng thÃ¡i vÃ  thÃªm thÃ´ng tin chi tiáº¿t vá»›i Æ°u tiÃªn plate memory
        if result['success'] and result['plates']:
            result['plate'] = result['plates'][0]  # Láº¥y biá»ƒn sá»‘ Ä‘áº§u tiÃªn (Ä‘Ã£ Ä‘Æ°á»£c sáº¯p xáº¿p Æ°u tiÃªn)

            # Kiá»ƒm tra xem cÃ³ tá»« plate memory khÃ´ng
            has_memory_result = result.get('plate_memory_results') and len(result['plate_memory_results']) > 0

            if has_memory_result:
                # Æ¯u tiÃªn cao cho plate memory
                memory_info = result['plate_memory_results'][0]
                result['status'] = 'detected_memory'
                result['status_message'] = f'ğŸ¯ Nháº­n diá»‡n tá»« Plate Memory: {result["plate"]} (similarity: {memory_info["similarity"]:.2f}, Æ°u tiÃªn cao)'
                result['detection_source'] = 'plate_memory'
                result['priority'] = 'high'
            elif result['confidence'] > 60:
                result['status'] = 'detected'
                result['status_message'] = f'ğŸ¤– OCR nháº­n diá»‡n: {result["plate"]} (Äá»™ tin cáº­y: {result["confidence"]:.1f}%)'
                result['detection_source'] = 'ocr'
                result['priority'] = 'normal'
            else:
                result['status'] = 'low_confidence'
                result['status_message'] = f'âš ï¸  PhÃ¡t hiá»‡n biá»ƒn sá»‘: {result["plate"]} nhÆ°ng Ä‘á»™ tin cáº­y tháº¥p ({result["confidence"]:.1f}%)'
                result['detection_source'] = 'ocr'
                result['priority'] = 'low'
        else:
            result['status'] = 'no_plate'
            result['status_message'] = 'KhÃ´ng phÃ¡t hiá»‡n biá»ƒn sá»‘ trong áº£nh'
            result['detection_source'] = 'none'
            result['priority'] = 'none'

        # Log káº¿t quáº£ chi tiáº¿t Ä‘á»ƒ debug
        print(f"ğŸ¯ [{camera_type.upper()}] {result['status_message']} - Time: {result['processing_time']:.2f}s")
        if result['success'] and result['plates']:
            print(f"ğŸ“‹ Detected plates: {result['plates']}")
            if result.get('plate_memory_results'):
                print(f"ğŸ§  Memory results: {[r['plate_text'] for r in result['plate_memory_results']]}")
        else:
            print(f"âŒ No plates detected in {camera_type} camera")

        return jsonify(result)

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Lá»—i server: {str(e)}',
            'plates': [],
            'confidence': 0,
            'processing_time': 0,
            'status': 'error'
        })

@app.route('/health', methods=['GET'])
def health_check():
    """Kiá»ƒm tra tráº¡ng thÃ¡i API"""
    return jsonify({
        'status': 'ok',
        'message': 'API nháº­n diá»‡n biá»ƒn sá»‘ Ä‘ang hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng',
        'models_loaded': True,
        'version': '1.0.0',
        'endpoints': {
            'POST /detect': 'Nháº­n dáº¡ng biá»ƒn sá»‘ tá»« file áº£nh upload',
            'POST /detect_base64': 'Nháº­n dáº¡ng biá»ƒn sá»‘ tá»« base64 (real-time)',
            'GET /health': 'Kiá»ƒm tra tráº¡ng thÃ¡i API',
            'GET /info': 'ThÃ´ng tin chi tiáº¿t vá» API'
        }
    }), 200

@app.route('/info', methods=['GET'])
def get_info():
    """ThÃ´ng tin chi tiáº¿t vá» API"""
    return jsonify({
        'api_name': 'License Plate Recognition API',
        'version': '2.0.0',
        'description': 'API nháº­n diá»‡n biá»ƒn sá»‘ xe Viá»‡t Nam vá»›i Æ°u tiÃªn Plate Memory',
        'models': {
            'detector': 'LP_detector.pt',
            'ocr': 'LP_ocr.pt',
            'confidence_threshold': 0.60,
            'plate_memory_threshold': 0.5
        },
        'features': [
            'ğŸ¯ Æ¯U TIÃŠN Plate Memory - Nháº­n dáº¡ng biá»ƒn sá»‘ Ä‘Ã£ gÃ¡n nhÃ£n trÆ°á»›c',
            'ğŸ¤– OCR fallback - Sá»­ dá»¥ng OCR khi khÃ´ng tÃ¬m tháº¥y trong memory',
            'ğŸ“¸ Nháº­n diá»‡n tá»« file áº£nh upload',
            'âš¡ Real-time tá»« base64 (camera, webcam)',
            'ğŸ§  Tá»± Ä‘á»™ng há»c vÃ  ghi nhá»› biá»ƒn sá»‘ má»›i',
            'ğŸš€ Tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ xá»­ lÃ½',
            'ğŸŒ Há»— trá»£ CORS cho web integration',
            'ğŸ“Š API quáº£n lÃ½ Plate Memory'
        ],
        'response_format': {
            'success': 'boolean - Tráº¡ng thÃ¡i xá»­ lÃ½',
            'plates': 'array - Danh sÃ¡ch biá»ƒn sá»‘ phÃ¡t hiá»‡n',
            'confidence': 'number - Äá»™ tin cáº­y (0-100)',
            'processing_time': 'number - Thá»i gian xá»­ lÃ½ (giÃ¢y)',
            'message': 'string - ThÃ´ng bÃ¡o káº¿t quáº£',
            'plate_memory_results': 'array - Káº¿t quáº£ tá»« plate memory',
            'detection_methods': 'object - Thá»‘ng kÃª phÆ°Æ¡ng phÃ¡p nháº­n dáº¡ng'
        }
    })

@app.route('/plate_memory/stats', methods=['GET'])
def get_plate_memory_stats():
    """Láº¥y thá»‘ng kÃª plate memory"""
    try:
        stats = plate_memory.get_statistics()
        return jsonify({
            'success': True,
            'stats': stats,
            'message': 'Thá»‘ng kÃª plate memory'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Lá»—i khi láº¥y thá»‘ng kÃª: {str(e)}'
        })

@app.route('/plate_memory/labeled', methods=['GET'])
def get_labeled_plates():
    """Láº¥y danh sÃ¡ch biá»ƒn sá»‘ Ä‘Ã£ gÃ¡n nhÃ£n"""
    try:
        labeled_plates = plate_memory.get_labeled_plates()
        return jsonify({
            'success': True,
            'labeled_plates': labeled_plates,
            'count': len(labeled_plates),
            'message': f'TÃ¬m tháº¥y {len(labeled_plates)} biá»ƒn sá»‘ Ä‘Ã£ gÃ¡n nhÃ£n'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Lá»—i khi láº¥y danh sÃ¡ch: {str(e)}'
        })

@app.route('/plate_memory/assign', methods=['POST'])
def assign_plate_label():
    """GÃ¡n nhÃ£n cho biá»ƒn sá»‘"""
    try:
        data = request.get_json()

        if not data or 'plate_id' not in data or 'plate_text' not in data:
            return jsonify({
                'success': False,
                'message': 'Thiáº¿u thÃ´ng tin plate_id hoáº·c plate_text'
            })

        plate_id = data['plate_id']
        plate_text = data['plate_text']

        success = plate_memory.assign_plate_text(plate_id, plate_text)

        if success:
            return jsonify({
                'success': True,
                'message': f'ÄÃ£ gÃ¡n nhÃ£n "{plate_text}" cho plate_id: {plate_id[:8]}...'
            })
        else:
            return jsonify({
                'success': False,
                'message': f'KhÃ´ng thá»ƒ gÃ¡n nhÃ£n cho plate_id: {plate_id}'
            })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Lá»—i khi gÃ¡n nhÃ£n: {str(e)}'
        })

@app.route('/debug/save_camera_image', methods=['POST'])
def save_camera_image():
    """Debug endpoint - LÆ°u áº£nh tá»« camera Ä‘á»ƒ kiá»ƒm tra"""
    try:
        data = request.get_json()

        if not data or 'image' not in data:
            return jsonify({
                'success': False,
                'message': 'KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u áº£nh base64'
            })

        base64_image = data['image']
        camera_type = data.get('type', 'unknown')

        # Chuyá»ƒn Ä‘á»•i base64 thÃ nh OpenCV image
        img = base64_to_image(base64_image)
        if img is None:
            return jsonify({
                'success': False,
                'message': 'KhÃ´ng thá»ƒ decode áº£nh base64'
            })

        # LÆ°u áº£nh Ä‘á»ƒ debug
        import os
        debug_dir = "debug_images"
        if not os.path.exists(debug_dir):
            os.makedirs(debug_dir)

        timestamp = int(time.time())
        filename = f"{debug_dir}/camera_{camera_type}_{timestamp}.jpg"
        cv2.imwrite(filename, img)

        # Thá»­ nháº­n dáº¡ng
        result = detect_license_plate_from_image(img)

        return jsonify({
            'success': True,
            'message': f'ÄÃ£ lÆ°u áº£nh debug: {filename}',
            'image_saved': filename,
            'detection_result': result,
            'image_size': f"{img.shape[1]}x{img.shape[0]}"
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Lá»—i debug: {str(e)}'
        })

if __name__ == '__main__':
    try:
        print("=" * 60)
        print("ğŸš— LICENSE PLATE RECOGNITION API SERVER v2.0")
        print("=" * 60)
        print("ğŸ¯ Chá»©c nÄƒng: Æ¯U TIÃŠN Plate Memory + OCR Fallback")
        print("ğŸ¤– AI Models: YOLOv5 Full (tÆ°Æ¡ng thÃ­ch plate memory)")
        print("ğŸ§  Plate Memory: Nháº­n dáº¡ng biá»ƒn sá»‘ Ä‘Ã£ gÃ¡n nhÃ£n TRÆ¯á»šC")
        print("âš¡ OCR: Sá»­ dá»¥ng khi khÃ´ng tÃ¬m tháº¥y trong memory")
        print("âœ… Models loaded successfully!")

        # Hiá»ƒn thá»‹ thá»‘ng kÃª plate memory
        try:
            stats = plate_memory.get_statistics()
            print(f"ğŸ“Š Plate Memory: {stats['labeled_plates']}/{stats['total_plates']} Ä‘Ã£ gÃ¡n nhÃ£n")
        except:
            print("ğŸ“Š Plate Memory: ÄÃ£ khá»Ÿi táº¡o")

        print("\nğŸ“¡ Available endpoints:")
        print("  ğŸ”¸ POST /detect              - Nháº­n dáº¡ng tá»« file áº£nh upload")
        print("  ğŸ”¸ POST /detect_base64       - Nháº­n dáº¡ng tá»« base64 (real-time)")
        print("  ğŸ”¸ GET  /health              - Kiá»ƒm tra tráº¡ng thÃ¡i API")
        print("  ğŸ”¸ GET  /info                - ThÃ´ng tin chi tiáº¿t API")
        print("  ğŸ”¸ GET  /plate_memory/stats  - Thá»‘ng kÃª plate memory")
        print("  ğŸ”¸ GET  /plate_memory/labeled - Danh sÃ¡ch biá»ƒn sá»‘ Ä‘Ã£ gÃ¡n nhÃ£n")
        print("  ğŸ”¸ POST /plate_memory/assign - GÃ¡n nhÃ£n cho biá»ƒn sá»‘")
        print("\nğŸŒ Server URL: http://localhost:5000")
        print("ğŸ”§ Mode: Production (threaded=True)")
        print("=" * 60)

        app.run(debug=False, host='0.0.0.0', port=5000, threaded=True)

    except Exception as e:
        print(f"âŒ Error starting server: {e}")
        print("ğŸ’¡ Kiá»ƒm tra:")
        print("   - Port 5000 cÃ³ Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng?")
        print("   - CÃ¡c file model cÃ³ tá»“n táº¡i?")
        print("   - Dependencies Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§?")
