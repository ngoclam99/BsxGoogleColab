{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# ğŸš— Nháº­n Dáº¡ng Biá»ƒn Sá»‘ Xe Viá»‡t Nam\n",
    "\n",
    "## Vietnamese License Plate Recognition (Fixed for PyTorch 2.6)\n",
    "\n",
    "### ğŸ¯ TÃ­nh nÄƒng:\n",
    "- PhÃ¡t hiá»‡n biá»ƒn sá»‘ xe trong áº£nh\n",
    "- Nháº­n dáº¡ng kÃ½ tá»± vÃ  sá»‘ trÃªn biá»ƒn sá»‘\n",
    "- Há»— trá»£ biá»ƒn sá»‘ 1 dÃ²ng vÃ  2 dÃ²ng\n",
    "\n",
    "### ğŸ“‹ HÆ°á»›ng dáº«n:\n",
    "1. **Chá»n GPU Runtime**: Runtime â†’ Change runtime type â†’ GPU\n",
    "2. **Cháº¡y tá»«ng cell theo thá»© tá»±** tá»« trÃªn xuá»‘ng dÆ°á»›i\n",
    "3. **Äá»£i cell hoÃ n thÃ nh** trÆ°á»›c khi cháº¡y cell tiáº¿p theo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup vÃ  Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Fix PyTorch 2.6 weights_only issue\n",
    "print(f\"ğŸ”§ PyTorch version: {torch.__version__}\")\n",
    "if hasattr(torch.serialization, 'add_safe_globals'):\n",
    "    print(\"ğŸ”§ Fixing PyTorch 2.6 weights_only issue...\")\n",
    "    # Add safe globals for YOLOv5\n",
    "    try:\n",
    "        from models.yolo import Model\n",
    "        torch.serialization.add_safe_globals([Model])\n",
    "        print(\"âœ… PyTorch fix applied!\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Will apply fix after cloning repository\")\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('BsxGoogleColab'):\n",
    "    print(\"ğŸ”„ Cloning repository...\")\n",
    "    !git clone https://github.com/ngoclam99/BsxGoogleColab.git\n",
    "    print(\"âœ… Clone successful!\")\n",
    "else:\n",
    "    print(\"âœ… Repository already exists!\")\n",
    "\n",
    "# Change directory\n",
    "os.chdir('BsxGoogleColab')\n",
    "print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add to Python path\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "if os.path.join(os.getcwd(), 'yolov5') not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'yolov5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## 2. Install Dependencies vÃ  Fix PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"ğŸ“¦ Installing dependencies...\")\n",
    "!pip install -q opencv-python-headless matplotlib numpy Pillow torch torchvision tqdm pyyaml requests pandas seaborn\n",
    "\n",
    "# Apply PyTorch 2.6 fix\n",
    "print(\"ğŸ”§ Applying PyTorch 2.6 compatibility fix...\")\n",
    "try:\n",
    "    import torch\n",
    "    # Import YOLOv5 models to add to safe globals\n",
    "    sys.path.append('yolov5')\n",
    "    from models.yolo import Model\n",
    "    from models.common import *\n",
    "    from utils.general import *\n",
    "    \n",
    "    # Add safe globals for PyTorch 2.6\n",
    "    if hasattr(torch.serialization, 'add_safe_globals'):\n",
    "        torch.serialization.add_safe_globals([\n",
    "            Model, Conv, Bottleneck, SPP, DWConv, Focus, \n",
    "            BottleneckCSP, C3, nn.Upsample, Concat, Detect\n",
    "        ])\n",
    "        print(\"âœ… PyTorch 2.6 fix applied successfully!\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ PyTorch version doesn't need fix\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Fix attempt failed: {e}\")\n",
    "    print(\"ğŸ’¡ Will try alternative loading method\")\n",
    "\n",
    "print(\"âœ… Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## 3. Import Libraries vÃ  Check Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libs"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import helper functions\n",
    "try:\n",
    "    import function.utils_rotate as utils_rotate\n",
    "    import function.helper as helper\n",
    "    print(\"âœ… Helper functions imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Error importing helpers: {e}\")\n",
    "\n",
    "# Check files\n",
    "required_files = {\n",
    "    'LP Detector Model': 'model/LP_detector.pt',\n",
    "    'LP OCR Model': 'model/LP_ocr.pt', \n",
    "    'YOLOv5 Directory': 'yolov5',\n",
    "    'Test Images': 'test_image'\n",
    "}\n",
    "\n",
    "print(\"ğŸ” Checking required files...\")\n",
    "all_files_ok = True\n",
    "for name, path in required_files.items():\n",
    "    if os.path.exists(path):\n",
    "        if os.path.isfile(path):\n",
    "            size = os.path.getsize(path) / (1024*1024)  # MB\n",
    "            print(f\"âœ… {name}: {path} ({size:.1f} MB)\")\n",
    "        else:\n",
    "            count = len(os.listdir(path)) if os.path.isdir(path) else 0\n",
    "            print(f\"âœ… {name}: {path} ({count} items)\")\n",
    "    else:\n",
    "        print(f\"âŒ {name}: {path} - MISSING\")\n",
    "        all_files_ok = False\n",
    "\n",
    "if all_files_ok:\n",
    "    print(\"\\nğŸŸ¢ All required files are ready!\")\n",
    "else:\n",
    "    print(\"\\nğŸ”´ Some files are missing! Check your repository.\")\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models"
   },
   "source": [
    "## 4. Load Models (vá»›i Fix cho PyTorch 2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_models"
   },
   "outputs": [],
   "source": [
    "# Load YOLOv5 models with PyTorch 2.6 fix\n",
    "print(\"ğŸ¤– Loading models with PyTorch 2.6 compatibility...\")\n",
    "print(\"â³ This may take 2-3 minutes...\")\n",
    "\n",
    "def load_model_safe(model_path, model_name):\n",
    "    \"\"\"Load model with PyTorch 2.6 compatibility\"\"\"\n",
    "    try:\n",
    "        # Method 1: Try with weights_only=False (for trusted models)\n",
    "        print(f\"ğŸ“¥ Loading {model_name} (Method 1)...\")\n",
    "        \n",
    "        # Temporarily set weights_only to False for trusted models\n",
    "        import torch\n",
    "        original_load = torch.load\n",
    "        \n",
    "        def safe_load(*args, **kwargs):\n",
    "            kwargs['weights_only'] = False\n",
    "            return original_load(*args, **kwargs)\n",
    "        \n",
    "        torch.load = safe_load\n",
    "        \n",
    "        model = torch.hub.load('yolov5', 'custom', \n",
    "                              path=model_path, \n",
    "                              force_reload=True, \n",
    "                              source='local',\n",
    "                              trust_repo=True)\n",
    "        \n",
    "        # Restore original torch.load\n",
    "        torch.load = original_load\n",
    "        \n",
    "        print(f\"âœ… {model_name} loaded successfully!\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Method 1 failed for {model_name}: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # Method 2: Direct model loading\n",
    "            print(f\"ğŸ“¥ Loading {model_name} (Method 2)...\")\n",
    "            \n",
    "            import sys\n",
    "            sys.path.append('yolov5')\n",
    "            from models.experimental import attempt_load\n",
    "            \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            model = attempt_load(model_path, map_location=device)\n",
    "            model.eval()\n",
    "            \n",
    "            print(f\"âœ… {model_name} loaded with Method 2!\")\n",
    "            return model\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"âŒ Method 2 also failed for {model_name}: {e2}\")\n",
    "            return None\n",
    "\n",
    "# Load models\n",
    "yolo_LP_detect = load_model_safe('model/LP_detector.pt', 'License Plate Detector')\n",
    "yolo_license_plate = load_model_safe('model/LP_ocr.pt', 'License Plate OCR')\n",
    "\n",
    "# Set confidence if models loaded successfully\n",
    "if yolo_license_plate is not None:\n",
    "    try:\n",
    "        yolo_license_plate.conf = 0.60\n",
    "        print(\"ğŸ”§ Confidence threshold set to 0.60\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Could not set confidence threshold\")\n",
    "\n",
    "# Check final status\n",
    "if yolo_LP_detect is not None and yolo_license_plate is not None:\n",
    "    print(\"\\nğŸ‰ ALL MODELS LOADED SUCCESSFULLY!\")\n",
    "    print(\"ğŸŸ¢ Ready for license plate recognition!\")\n",
    "else:\n",
    "    print(\"\\nâŒ FAILED TO LOAD MODELS!\")\n",
    "    print(\"ğŸ’¡ Solutions:\")\n",
    "    print(\"   1. Runtime â†’ Restart Runtime and try again\")\n",
    "    print(\"   2. Make sure you have GPU runtime selected\")\n",
    "    print(\"   3. Check if model files exist in repository\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "function"
   },
   "source": [
    "## 5. Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "detect_function"
   },
   "outputs": [],
   "source": [
    "def detect_license_plate(image_path):\n",
    "    \"\"\"Detect and recognize license plate with error handling\"\"\"\n",
    "    \n",
    "    # Check if models are loaded\n",
    "    if yolo_LP_detect is None or yolo_license_plate is None:\n",
    "        print(\"âŒ Models not loaded! Please run the model loading cell first.\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"ğŸ” Processing: {image_path}\")\n",
    "    \n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"âŒ Cannot read image: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        # Detect license plates\n",
    "        print(\"ğŸ“¸ Detecting license plates...\")\n",
    "        plates = yolo_LP_detect(img, size=640)\n",
    "        \n",
    "        # Handle different model types\n",
    "        if hasattr(plates, 'pandas'):\n",
    "            list_plates = plates.pandas().xyxy[0].values.tolist()\n",
    "        else:\n",
    "            # For direct model loading\n",
    "            list_plates = []\n",
    "            if len(plates) > 0:\n",
    "                for det in plates:\n",
    "                    if len(det):\n",
    "                        for *xyxy, conf, cls in det:\n",
    "                            if conf > 0.5:  # confidence threshold\n",
    "                                list_plates.append([float(x) for x in xyxy] + [float(conf), int(cls)])\n",
    "        \n",
    "        list_read_plates = set()\n",
    "        \n",
    "        print(f\"ğŸ¯ Found {len(list_plates)} license plate regions\")\n",
    "        \n",
    "        if len(list_plates) == 0:\n",
    "            # Try reading entire image\n",
    "            print(\"ğŸ”„ Trying to read entire image...\")\n",
    "            lp = helper.read_plate(yolo_license_plate, img)\n",
    "            if lp != \"unknown\":\n",
    "                list_read_plates.add(lp)\n",
    "        else:\n",
    "            # Process each detected plate\n",
    "            for i, plate in enumerate(list_plates):\n",
    "                print(f\"ğŸ“ Reading plate {i+1}/{len(list_plates)}...\")\n",
    "                \n",
    "                x = int(plate[0])\n",
    "                y = int(plate[1])\n",
    "                w = int(plate[2] - plate[0])\n",
    "                h = int(plate[3] - plate[1])\n",
    "                \n",
    "                # Crop license plate\n",
    "                crop_img = img[y:y+h, x:x+w]\n",
    "                \n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "                \n",
    "                # Try different image processing\n",
    "                found = False\n",
    "                for cc in range(0, 2):\n",
    "                    for ct in range(0, 2):\n",
    "                        try:\n",
    "                            processed_img = utils_rotate.deskew(crop_img, cc, ct)\n",
    "                            lp = helper.read_plate(yolo_license_plate, processed_img)\n",
    "                            if lp != \"unknown\":\n",
    "                                list_read_plates.add(lp)\n",
    "                                found = True\n",
    "                                break\n",
    "                        except Exception as e:\n",
    "                            print(f\"âš ï¸ Error processing variation {cc},{ct}: {e}\")\n",
    "                            continue\n",
    "                    if found:\n",
    "                        break\n",
    "        \n",
    "        # Add text to image\n",
    "        if list_read_plates:\n",
    "            y_offset = 30\n",
    "            for plate_text in list_read_plates:\n",
    "                cv2.putText(img, str(plate_text), (10, y_offset), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                y_offset += 40\n",
    "        \n",
    "        if list_read_plates:\n",
    "            print(f\"âœ… Result: {list_read_plates}\")\n",
    "        else:\n",
    "            print(\"âŒ No license plate recognized\")\n",
    "        \n",
    "        return img, list_read_plates\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during detection: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "print(\"âœ… Detection function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## 6. Test vá»›i áº¢nh Máº«u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_sample"
   },
   "outputs": [],
   "source": [
    "# Import glob if not already imported\n",
    "try:\n",
    "    glob\n",
    "except NameError:\n",
    "    import glob\n",
    "    print(\"ğŸ“¦ Imported glob module\")\n",
    "\n",
    "# Find test images\n",
    "test_images = glob.glob(\"test_image/*.jpg\") + glob.glob(\"test_image/*.png\") + glob.glob(\"test_image/*.jpeg\")\n",
    "\n",
    "if test_images:\n",
    "    print(f\"ğŸ–¼ï¸ Found {len(test_images)} test images:\")\n",
    "    for i, img in enumerate(test_images):\n",
    "        print(f\"   {i}: {img}\")\n",
    "    \n",
    "    # Test first image\n",
    "    test_index = 0  # Change this to test different images\n",
    "    \n",
    "    if test_index < len(test_images):\n",
    "        test_img = test_images[test_index]\n",
    "        \n",
    "        print(f\"\\nğŸš€ Testing: {test_img}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        result_img, detected_plates = detect_license_plate(test_img)\n",
    "        \n",
    "        if result_img is not None:\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(f\"ğŸ¯ FINAL RESULT: {detected_plates if detected_plates else 'NO DETECTION'}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Display results\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            \n",
    "            # Original image\n",
    "            original = cv2.imread(test_img)\n",
    "            axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title(\"ğŸ–¼ï¸ Original Image\", fontsize=14, fontweight='bold')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Result image\n",
    "            axes[1].imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "            result_title = f\"ğŸ¯ Result: {detected_plates if detected_plates else 'No detection'}\"\n",
    "            axes[1].set_title(result_title, fontsize=14, fontweight='bold')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Summary\n",
    "            print(f\"\\nğŸ“Š SUMMARY:\")\n",
    "            print(f\"   ğŸ“ File: {test_img}\")\n",
    "            print(f\"   ğŸ“ Size: {original.shape[1]}x{original.shape[0]}\")\n",
    "            print(f\"   ğŸ”¢ Plates found: {len(detected_plates) if detected_plates else 0}\")\n",
    "            if detected_plates:\n",
    "                for i, plate in enumerate(detected_plates, 1):\n",
    "                    print(f\"   ğŸš— Plate {i}: {plate}\")\n",
    "        else:\n",
    "            print(\"âŒ Failed to process image\")\n",
    "    else:\n",
    "        print(f\"âŒ Invalid index {test_index}. Choose from 0 to {len(test_images)-1}\")\n",
    "else:\n",
    "    print(\"âŒ No test images found in test_image/ directory\")\n",
    "    print(\"ğŸ’¡ Make sure your repository has test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## 7. Upload áº¢nh Cá»§a Báº¡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_test"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "def upload_and_test():\n",
    "    \"\"\"Upload and test your own image\"\"\"\n",
    "    print(\"ğŸ“¤ Select image file from your computer...\")\n",
    "    print(\"ğŸ’¡ Supported formats: .jpg, .jpeg, .png\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"\\nğŸ” Processing uploaded image: {filename}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Save uploaded file\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(uploaded[filename])\n",
    "        \n",
    "        # Process image\n",
    "        result_img, detected_plates = detect_license_plate(filename)\n",
    "        \n",
    "        if result_img is not None:\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(f\"ğŸ¯ RESULT: {detected_plates if detected_plates else 'NO DETECTION'}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Display results\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            \n",
    "            # Original\n",
    "            original = cv2.imread(filename)\n",
    "            axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title(\"ğŸ–¼ï¸ Your Image\", fontsize=14, fontweight='bold')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Result\n",
    "            axes[1].imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "            result_title = f\"ğŸ¯ Result: {detected_plates if detected_plates else 'No detection'}\"\n",
    "            axes[1].set_title(result_title, fontsize=14, fontweight='bold')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Summary\n",
    "            print(f\"\\nğŸ“Š SUMMARY:\")\n",
    "            print(f\"   ğŸ“ File: {filename}\")\n",
    "            print(f\"   ğŸ“ Size: {original.shape[1]}x{original.shape[0]}\")\n",
    "            if detected_plates:\n",
    "                for i, plate in enumerate(detected_plates, 1):\n",
    "                    print(f\"   ğŸš— License Plate {i}: {plate}\")\n",
    "            else:\n",
    "                print(\"   âŒ No license plate detected\")\n",
    "                print(\"   ğŸ’¡ Try with a clearer image or different angle\")\n",
    "        else:\n",
    "            print(\"âŒ Failed to process uploaded image\")\n",
    "\n",
    "# Uncomment the line below to upload and test your image\n",
    "# upload_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructions"
   },
   "source": [
    "## ğŸ“ HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng\n",
    "\n",
    "### ğŸš€ CÃ¡ch sá»­ dá»¥ng:\n",
    "1. **Cháº¡y cells 1-4** Ä‘á»ƒ setup vÃ  load models\n",
    "2. **Cháº¡y cell 5** Ä‘á»ƒ Ä‘á»‹nh nghÄ©a hÃ m detection\n",
    "3. **Cháº¡y cell 6** Ä‘á»ƒ test vá»›i áº£nh máº«u\n",
    "4. **Cháº¡y cell 7** Ä‘á»ƒ upload áº£nh cá»§a báº¡n (uncomment dÃ²ng cuá»‘i)\n",
    "\n",
    "### ğŸ’¡ Tips Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t:\n",
    "- **Chá»n GPU Runtime** Ä‘á»ƒ xá»­ lÃ½ nhanh hÆ¡n\n",
    "- **Sá»­ dá»¥ng áº£nh rÃµ nÃ©t** vÃ  cháº¥t lÆ°á»£ng cao\n",
    "- **Biá»ƒn sá»‘ khÃ´ng bá»‹ che khuáº¥t** hoáº·c má»\n",
    "- **GÃ³c chá»¥p tháº³ng** cho káº¿t quáº£ tá»‘t nháº¥t\n",
    "- **Ãnh sÃ¡ng Ä‘á»§** Ä‘á»ƒ nhÃ¬n rÃµ kÃ½ tá»±\n",
    "\n",
    "### ğŸ”§ Kháº¯c phá»¥c sá»± cá»‘:\n",
    "- **Models khÃ´ng load Ä‘Æ°á»£c**: \n",
    "  - Runtime â†’ Restart Runtime vÃ  cháº¡y láº¡i\n",
    "  - Äáº£m báº£o Ä‘Ã£ chá»n GPU runtime\n",
    "- **Lá»—i import**: Kiá»ƒm tra cáº¥u trÃºc repository\n",
    "- **KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c**: \n",
    "  - Thá»­ áº£nh khÃ¡c rÃµ nÃ©t hÆ¡n\n",
    "  - Kiá»ƒm tra biá»ƒn sá»‘ cÃ³ bá»‹ che khÃ´ng\n",
    "  - Thá»­ gÃ³c chá»¥p khÃ¡c\n",
    "\n",
    "### ğŸ†˜ Náº¿u váº«n gáº·p lá»—i PyTorch 2.6:\n",
    "1. **Restart Runtime** vÃ  cháº¡y láº¡i tá»« Ä‘áº§u\n",
    "2. **Äáº£m báº£o GPU runtime** Ä‘Æ°á»£c chá»n\n",
    "3. **Kiá»ƒm tra repository** cÃ³ Ä‘áº§y Ä‘á»§ files khÃ´ng\n",
    "\n",
    "---\n",
    "**ğŸš— ChÃºc báº¡n nháº­n dáº¡ng biá»ƒn sá»‘ thÃ nh cÃ´ng! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
