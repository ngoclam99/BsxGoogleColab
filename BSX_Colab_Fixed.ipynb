{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üöó Nh·∫≠n D·∫°ng Bi·ªÉn S·ªë Xe Vi·ªát Nam\n",
    "\n",
    "## Vietnamese License Plate Recognition (Fixed for PyTorch 2.6)\n",
    "\n",
    "### üéØ T√≠nh nƒÉng:\n",
    "- Ph√°t hi·ªán bi·ªÉn s·ªë xe trong ·∫£nh\n",
    "- Nh·∫≠n d·∫°ng k√Ω t·ª± v√† s·ªë tr√™n bi·ªÉn s·ªë\n",
    "- H·ªó tr·ª£ bi·ªÉn s·ªë 1 d√≤ng v√† 2 d√≤ng\n",
    "\n",
    "### üìã H∆∞·ªõng d·∫´n:\n",
    "1. **Ch·ªçn GPU Runtime**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. **Ch·∫°y t·ª´ng cell theo th·ª© t·ª±** t·ª´ tr√™n xu·ªëng d∆∞·ªõi\n",
    "3. **ƒê·ª£i cell ho√†n th√†nh** tr∆∞·ªõc khi ch·∫°y cell ti·∫øp theo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup v√† Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Fix PyTorch 2.6 weights_only issue\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "if hasattr(torch.serialization, 'add_safe_globals'):\n",
    "    print(\"üîß Fixing PyTorch 2.6 weights_only issue...\")\n",
    "    # Add safe globals for YOLOv5\n",
    "    try:\n",
    "        from models.yolo import Model\n",
    "        torch.serialization.add_safe_globals([Model])\n",
    "        print(\"‚úÖ PyTorch fix applied!\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Will apply fix after cloning repository\")\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('BsxGoogleColab'):\n",
    "    print(\"üîÑ Cloning repository...\")\n",
    "    !git clone https://github.com/ngoclam99/BsxGoogleColab.git\n",
    "    print(\"‚úÖ Clone successful!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists!\")\n",
    "\n",
    "# Change directory\n",
    "os.chdir('BsxGoogleColab')\n",
    "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add to Python path\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "if os.path.join(os.getcwd(), 'yolov5') not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'yolov5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## 2. Install Dependencies v√† Fix PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install -q opencv-python-headless matplotlib numpy Pillow torch torchvision tqdm pyyaml requests pandas seaborn\n",
    "\n",
    "# Apply PyTorch 2.6 fix\n",
    "print(\"üîß Applying PyTorch 2.6 compatibility fix...\")\n",
    "try:\n",
    "    import torch\n",
    "    # Import YOLOv5 models to add to safe globals\n",
    "    sys.path.append('yolov5')\n",
    "    from models.yolo import Model\n",
    "    from models.common import *\n",
    "    from utils.general import *\n",
    "    \n",
    "    # Add safe globals for PyTorch 2.6\n",
    "    if hasattr(torch.serialization, 'add_safe_globals'):\n",
    "        torch.serialization.add_safe_globals([\n",
    "            Model, Conv, Bottleneck, SPP, DWConv, Focus, \n",
    "            BottleneckCSP, C3, nn.Upsample, Concat, Detect\n",
    "        ])\n",
    "        print(\"‚úÖ PyTorch 2.6 fix applied successfully!\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è PyTorch version doesn't need fix\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Fix attempt failed: {e}\")\n",
    "    print(\"üí° Will try alternative loading method\")\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## 3. Import Libraries v√† Check Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_libs"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import helper functions\n",
    "try:\n",
    "    import function.utils_rotate as utils_rotate\n",
    "    import function.helper as helper\n",
    "    print(\"‚úÖ Helper functions imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing helpers: {e}\")\n",
    "\n",
    "# Check files\n",
    "required_files = {\n",
    "    'LP Detector Model': 'model/LP_detector.pt',\n",
    "    'LP OCR Model': 'model/LP_ocr.pt', \n",
    "    'YOLOv5 Directory': 'yolov5',\n",
    "    'Test Images': 'test_image'\n",
    "}\n",
    "\n",
    "print(\"üîç Checking required files...\")\n",
    "all_files_ok = True\n",
    "for name, path in required_files.items():\n",
    "    if os.path.exists(path):\n",
    "        if os.path.isfile(path):\n",
    "            size = os.path.getsize(path) / (1024*1024)  # MB\n",
    "            print(f\"‚úÖ {name}: {path} ({size:.1f} MB)\")\n",
    "        else:\n",
    "            count = len(os.listdir(path)) if os.path.isdir(path) else 0\n",
    "            print(f\"‚úÖ {name}: {path} ({count} items)\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: {path} - MISSING\")\n",
    "        all_files_ok = False\n",
    "\n",
    "if all_files_ok:\n",
    "    print(\"\\nüü¢ All required files are ready!\")\n",
    "else:\n",
    "    print(\"\\nüî¥ Some files are missing! Check your repository.\")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models"
   },
   "source": [
    "## 4. Load Models (v·ªõi Fix cho PyTorch 2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_models"
   },
   "outputs": [],
   "source": [
    "# Load YOLOv5 models with PyTorch 2.6 fix\n",
    "print(\"ü§ñ Loading models with PyTorch 2.6 compatibility...\")\n",
    "print(\"‚è≥ This may take 2-3 minutes...\")\n",
    "\n",
    "def load_model_safe(model_path, model_name):\n",
    "    \"\"\"Load model with PyTorch 2.6 compatibility\"\"\"\n",
    "    try:\n",
    "        # Method 1: Try with weights_only=False (for trusted models)\n",
    "        print(f\"üì• Loading {model_name} (Method 1)...\")\n",
    "        \n",
    "        # Temporarily set weights_only to False for trusted models\n",
    "        import torch\n",
    "        original_load = torch.load\n",
    "        \n",
    "        def safe_load(*args, **kwargs):\n",
    "            kwargs['weights_only'] = False\n",
    "            return original_load(*args, **kwargs)\n",
    "        \n",
    "        torch.load = safe_load\n",
    "        \n",
    "        model = torch.hub.load('yolov5', 'custom', \n",
    "                              path=model_path, \n",
    "                              force_reload=True, \n",
    "                              source='local',\n",
    "                              trust_repo=True)\n",
    "        \n",
    "        # Restore original torch.load\n",
    "        torch.load = original_load\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} loaded successfully!\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Method 1 failed for {model_name}: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # Method 2: Direct model loading\n",
    "            print(f\"üì• Loading {model_name} (Method 2)...\")\n",
    "            \n",
    "            import sys\n",
    "            sys.path.append('yolov5')\n",
    "            from models.experimental import attempt_load\n",
    "            \n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            model = attempt_load(model_path, map_location=device)\n",
    "            model.eval()\n",
    "            \n",
    "            print(f\"‚úÖ {model_name} loaded with Method 2!\")\n",
    "            return model\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Method 2 also failed for {model_name}: {e2}\")\n",
    "            return None\n",
    "\n",
    "# Load models\n",
    "yolo_LP_detect = load_model_safe('model/LP_detector.pt', 'License Plate Detector')\n",
    "yolo_license_plate = load_model_safe('model/LP_ocr.pt', 'License Plate OCR')\n",
    "\n",
    "# Set confidence if models loaded successfully\n",
    "if yolo_license_plate is not None:\n",
    "    try:\n",
    "        yolo_license_plate.conf = 0.60\n",
    "        print(\"üîß Confidence threshold set to 0.60\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Could not set confidence threshold\")\n",
    "\n",
    "# Check final status\n",
    "if yolo_LP_detect is not None and yolo_license_plate is not None:\n",
    "    print(\"\\nüéâ ALL MODELS LOADED SUCCESSFULLY!\")\n",
    "    print(\"üü¢ Ready for license plate recognition!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå FAILED TO LOAD MODELS!\")\n",
    "    print(\"üí° Solutions:\")\n",
    "    print(\"   1. Runtime ‚Üí Restart Runtime and try again\")\n",
    "    print(\"   2. Make sure you have GPU runtime selected\")\n",
    "    print(\"   3. Check if model files exist in repository\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "function"
   },
   "source": [
    "## 5. Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "detect_function"
   },
   "outputs": [],
   "source": [
    "def detect_license_plate(image_path):\n",
    "    \"\"\"Detect and recognize license plate with error handling\"\"\"\n",
    "    \n",
    "    # Check if models are loaded\n",
    "    if yolo_LP_detect is None or yolo_license_plate is None:\n",
    "        print(\"‚ùå Models not loaded! Please run the model loading cell first.\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"üîç Processing: {image_path}\")\n",
    "    \n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"‚ùå Cannot read image: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        # Detect license plates\n",
    "        print(\"üì∏ Detecting license plates...\")\n",
    "        plates = yolo_LP_detect(img, size=640)\n",
    "        \n",
    "        # Handle different model types\n",
    "        if hasattr(plates, 'pandas'):\n",
    "            list_plates = plates.pandas().xyxy[0].values.tolist()\n",
    "        else:\n",
    "            # For direct model loading\n",
    "            list_plates = []\n",
    "            if len(plates) > 0:\n",
    "                for det in plates:\n",
    "                    if len(det):\n",
    "                        for *xyxy, conf, cls in det:\n",
    "                            if conf > 0.5:  # confidence threshold\n",
    "                                list_plates.append([float(x) for x in xyxy] + [float(conf), int(cls)])\n",
    "        \n",
    "        list_read_plates = set()\n",
    "        \n",
    "        print(f\"üéØ Found {len(list_plates)} license plate regions\")\n",
    "        \n",
    "        if len(list_plates) == 0:\n",
    "            # Try reading entire image\n",
    "            print(\"üîÑ Trying to read entire image...\")\n",
    "            lp = helper.read_plate(yolo_license_plate, img)\n",
    "            if lp != \"unknown\":\n",
    "                list_read_plates.add(lp)\n",
    "        else:\n",
    "            # Process each detected plate\n",
    "            for i, plate in enumerate(list_plates):\n",
    "                print(f\"üìù Reading plate {i+1}/{len(list_plates)}...\")\n",
    "                \n",
    "                x = int(plate[0])\n",
    "                y = int(plate[1])\n",
    "                w = int(plate[2] - plate[0])\n",
    "                h = int(plate[3] - plate[1])\n",
    "                \n",
    "                # Crop license plate\n",
    "                crop_img = img[y:y+h, x:x+w]\n",
    "                \n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "                \n",
    "                # Try different image processing\n",
    "                found = False\n",
    "                for cc in range(0, 2):\n",
    "                    for ct in range(0, 2):\n",
    "                        try:\n",
    "                            processed_img = utils_rotate.deskew(crop_img, cc, ct)\n",
    "                            lp = helper.read_plate(yolo_license_plate, processed_img)\n",
    "                            if lp != \"unknown\":\n",
    "                                list_read_plates.add(lp)\n",
    "                                found = True\n",
    "                                break\n",
    "                        except Exception as e:\n",
    "                            print(f\"‚ö†Ô∏è Error processing variation {cc},{ct}: {e}\")\n",
    "                            continue\n",
    "                    if found:\n",
    "                        break\n",
    "        \n",
    "        # Add text to image\n",
    "        if list_read_plates:\n",
    "            y_offset = 30\n",
    "            for plate_text in list_read_plates:\n",
    "                cv2.putText(img, str(plate_text), (10, y_offset), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                y_offset += 40\n",
    "        \n",
    "        if list_read_plates:\n",
    "            print(f\"‚úÖ Result: {list_read_plates}\")\n",
    "        else:\n",
    "            print(\"‚ùå No license plate recognized\")\n",
    "        \n",
    "        return img, list_read_plates\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during detection: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "print(\"‚úÖ Detection function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## 6. Test v·ªõi ·∫¢nh M·∫´u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_sample"
   },
   "outputs": [],
   "source": [
    "# Import glob if not already imported\n",
    "try:\n",
    "    glob\n",
    "except NameError:\n",
    "    import glob\n",
    "    print(\"üì¶ Imported glob module\")\n",
    "\n",
    "# Find test images\n",
    "test_images = glob.glob(\"test_image/*.jpg\") + glob.glob(\"test_image/*.png\") + glob.glob(\"test_image/*.jpeg\")\n",
    "\n",
    "if test_images:\n",
    "    print(f\"üñºÔ∏è Found {len(test_images)} test images:\")\n",
    "    for i, img in enumerate(test_images):\n",
    "        print(f\"   {i}: {img}\")\n",
    "    \n",
    "    # Test first image\n",
    "    test_index = 0  # Change this to test different images\n",
    "    \n",
    "    if test_index < len(test_images):\n",
    "        test_img = test_images[test_index]\n",
    "        \n",
    "        print(f\"\\nüöÄ Testing: {test_img}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        result_img, detected_plates = detect_license_plate(test_img)\n",
    "        \n",
    "        if result_img is not None:\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(f\"üéØ FINAL RESULT: {detected_plates if detected_plates else 'NO DETECTION'}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Display results\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            \n",
    "            # Original image\n",
    "            original = cv2.imread(test_img)\n",
    "            axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title(\"üñºÔ∏è Original Image\", fontsize=14, fontweight='bold')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Result image\n",
    "            axes[1].imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "            result_title = f\"üéØ Result: {detected_plates if detected_plates else 'No detection'}\"\n",
    "            axes[1].set_title(result_title, fontsize=14, fontweight='bold')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Summary\n",
    "            print(f\"\\nüìä SUMMARY:\")\n",
    "            print(f\"   üìÅ File: {test_img}\")\n",
    "            print(f\"   üìè Size: {original.shape[1]}x{original.shape[0]}\")\n",
    "            print(f\"   üî¢ Plates found: {len(detected_plates) if detected_plates else 0}\")\n",
    "            if detected_plates:\n",
    "                for i, plate in enumerate(detected_plates, 1):\n",
    "                    print(f\"   üöó Plate {i}: {plate}\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to process image\")\n",
    "    else:\n",
    "        print(f\"‚ùå Invalid index {test_index}. Choose from 0 to {len(test_images)-1}\")\n",
    "else:\n",
    "    print(\"‚ùå No test images found in test_image/ directory\")\n",
    "    print(\"üí° Make sure your repository has test images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## 7. Upload ·∫¢nh C·ªßa B·∫°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_test"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "def upload_and_test():\n",
    "    \"\"\"Upload and test your own image\"\"\"\n",
    "    print(\"üì§ Select image file from your computer...\")\n",
    "    print(\"üí° Supported formats: .jpg, .jpeg, .png\")\n",
    "    \n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"\\nüîç Processing uploaded image: {filename}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Save uploaded file\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(uploaded[filename])\n",
    "        \n",
    "        # Process image\n",
    "        result_img, detected_plates = detect_license_plate(filename)\n",
    "        \n",
    "        if result_img is not None:\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(f\"üéØ RESULT: {detected_plates if detected_plates else 'NO DETECTION'}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Display results\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "            \n",
    "            # Original\n",
    "            original = cv2.imread(filename)\n",
    "            axes[0].imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "            axes[0].set_title(\"üñºÔ∏è Your Image\", fontsize=14, fontweight='bold')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Result\n",
    "            axes[1].imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
    "            result_title = f\"üéØ Result: {detected_plates if detected_plates else 'No detection'}\"\n",
    "            axes[1].set_title(result_title, fontsize=14, fontweight='bold')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Summary\n",
    "            print(f\"\\nüìä SUMMARY:\")\n",
    "            print(f\"   üìÅ File: {filename}\")\n",
    "            print(f\"   üìè Size: {original.shape[1]}x{original.shape[0]}\")\n",
    "            if detected_plates:\n",
    "                for i, plate in enumerate(detected_plates, 1):\n",
    "                    print(f\"   üöó License Plate {i}: {plate}\")\n",
    "            else:\n",
    "                print(\"   ‚ùå No license plate detected\")\n",
    "                print(\"   üí° Try with a clearer image or different angle\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to process uploaded image\")\n",
    "\n",
    "# Uncomment the line below to upload and test your image\n",
    "# upload_and_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "instructions"
   },
   "source": [
    "## üìù H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng\n",
    "\n",
    "### üöÄ C√°ch s·ª≠ d·ª•ng:\n",
    "1. **Ch·∫°y cells 1-4** ƒë·ªÉ setup v√† load models\n",
    "2. **Ch·∫°y cell 5** ƒë·ªÉ ƒë·ªãnh nghƒ©a h√†m detection\n",
    "3. **Ch·∫°y cell 6** ƒë·ªÉ test v·ªõi ·∫£nh m·∫´u\n",
    "4. **Ch·∫°y cell 7** ƒë·ªÉ upload ·∫£nh c·ªßa b·∫°n (uncomment d√≤ng cu·ªëi)\n",
    "\n",
    "### üí° Tips ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët:\n",
    "- **Ch·ªçn GPU Runtime** ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n\n",
    "- **S·ª≠ d·ª•ng ·∫£nh r√µ n√©t** v√† ch·∫•t l∆∞·ª£ng cao\n",
    "- **Bi·ªÉn s·ªë kh√¥ng b·ªã che khu·∫•t** ho·∫∑c m·ªù\n",
    "- **G√≥c ch·ª•p th·∫≥ng** cho k·∫øt qu·∫£ t·ªët nh·∫•t\n",
    "- **√Ånh s√°ng ƒë·ªß** ƒë·ªÉ nh√¨n r√µ k√Ω t·ª±\n",
    "\n",
    "### üîß Kh·∫Øc ph·ª•c s·ª± c·ªë:\n",
    "- **Models kh√¥ng load ƒë∆∞·ª£c**: \n",
    "  - Runtime ‚Üí Restart Runtime v√† ch·∫°y l·∫°i\n",
    "  - ƒê·∫£m b·∫£o ƒë√£ ch·ªçn GPU runtime\n",
    "- **L·ªói import**: Ki·ªÉm tra c·∫•u tr√∫c repository\n",
    "- **Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c**: \n",
    "  - Th·ª≠ ·∫£nh kh√°c r√µ n√©t h∆°n\n",
    "  - Ki·ªÉm tra bi·ªÉn s·ªë c√≥ b·ªã che kh√¥ng\n",
    "  - Th·ª≠ g√≥c ch·ª•p kh√°c\n",
    "\n",
    "### üÜò N·∫øu v·∫´n g·∫∑p l·ªói PyTorch 2.6:\n",
    "1. **Restart Runtime** v√† ch·∫°y l·∫°i t·ª´ ƒë·∫ßu\n",
    "2. **ƒê·∫£m b·∫£o GPU runtime** ƒë∆∞·ª£c ch·ªçn\n",
    "3. **Ki·ªÉm tra repository** c√≥ ƒë·∫ßy ƒë·ªß files kh√¥ng\n",
    "\n",
    "---\n",
    "**üöó Ch√∫c b·∫°n nh·∫≠n d·∫°ng bi·ªÉn s·ªë th√†nh c√¥ng! üéâ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
